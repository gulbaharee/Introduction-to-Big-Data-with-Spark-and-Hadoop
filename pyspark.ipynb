{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b89aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/gulbahar/opt/anaconda3/lib/python3.8/site-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/gulbahar/opt/anaconda3/lib/python3.8/site-packages (from pyspark) (0.10.9.7)\n",
      "\u001b[33mWARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
      "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "\u001b[33mWARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "Requirement already satisfied: pandas in /Users/gulbahar/opt/anaconda3/lib/python3.8/site-packages (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/gulbahar/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/gulbahar/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/gulbahar/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gulbahar/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install findspark\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5f53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark  # This helps us find and use Apache Spark\n",
    "findspark.init()  # Initialize findspark to locate Spark\n",
    "from pyspark.sql import SparkSession  \n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, DateType\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1f4a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession is active and ready to use.\n"
     ]
    }
   ],
   "source": [
    " # Initialize a Spark Session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"COVID-19 Data Analysis\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Check if the Spark Session is active\n",
    "if 'spark' in locals() and isinstance(spark, SparkSession):\n",
    "    print(\"SparkSession is active and ready to use.\")\n",
    "else:\n",
    "    print(\"SparkSession is not active. Please create a SparkSession.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409d7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccination_data = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/KpHDlIzdtR63BdTofl1mOg/owid-covid-latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ec2fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>last_updated_date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>population</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2024-08-04</td>\n",
       "      <td>235214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>4.112877e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OWID_AFR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Africa</td>\n",
       "      <td>2024-08-04</td>\n",
       "      <td>13145380.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.143</td>\n",
       "      <td>259117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426737e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2024-08-04</td>\n",
       "      <td>335047.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3605.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.89</td>\n",
       "      <td>78.57</td>\n",
       "      <td>0.795</td>\n",
       "      <td>2.842318e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DZA</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>2024-08-04</td>\n",
       "      <td>272139.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.571</td>\n",
       "      <td>6881.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.4</td>\n",
       "      <td>83.741</td>\n",
       "      <td>1.90</td>\n",
       "      <td>76.88</td>\n",
       "      <td>0.748</td>\n",
       "      <td>4.490323e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASM</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>2024-08-04</td>\n",
       "      <td>8359.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.429500e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iso_code continent        location last_updated_date  total_cases  \\\n",
       "0       AFG      Asia     Afghanistan        2024-08-04     235214.0   \n",
       "1  OWID_AFR       NaN          Africa        2024-08-04   13145380.0   \n",
       "2       ALB    Europe         Albania        2024-08-04     335047.0   \n",
       "3       DZA    Africa         Algeria        2024-08-04     272139.0   \n",
       "4       ASM   Oceania  American Samoa        2024-08-04       8359.0   \n",
       "\n",
       "   new_cases  new_cases_smoothed  total_deaths  new_deaths  \\\n",
       "0        0.0               0.000        7998.0         0.0   \n",
       "1       36.0               5.143      259117.0         0.0   \n",
       "2        0.0               0.000        3605.0         0.0   \n",
       "3       18.0               2.571        6881.0         0.0   \n",
       "4        0.0               0.000          34.0         0.0   \n",
       "\n",
       "   new_deaths_smoothed  ...  male_smokers  handwashing_facilities  \\\n",
       "0                  0.0  ...           NaN                  37.746   \n",
       "1                  0.0  ...           NaN                     NaN   \n",
       "2                  0.0  ...          51.2                     NaN   \n",
       "3                  0.0  ...          30.4                  83.741   \n",
       "4                  0.0  ...           NaN                     NaN   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                        0.50            64.83                    0.511   \n",
       "1                         NaN              NaN                      NaN   \n",
       "2                        2.89            78.57                    0.795   \n",
       "3                        1.90            76.88                    0.748   \n",
       "4                         NaN            73.74                      NaN   \n",
       "\n",
       "     population  excess_mortality_cumulative_absolute  \\\n",
       "0  4.112877e+07                                   NaN   \n",
       "1  1.426737e+09                                   NaN   \n",
       "2  2.842318e+06                                   NaN   \n",
       "3  4.490323e+07                                   NaN   \n",
       "4  4.429500e+04                                   NaN   \n",
       "\n",
       "   excess_mortality_cumulative  excess_mortality  \\\n",
       "0                          NaN               NaN   \n",
       "1                          NaN               NaN   \n",
       "2                          NaN               NaN   \n",
       "3                          NaN               NaN   \n",
       "4                          NaN               NaN   \n",
       "\n",
       "   excess_mortality_cumulative_per_million  \n",
       "0                                      NaN  \n",
       "1                                      NaN  \n",
       "2                                      NaN  \n",
       "3                                      NaN  \n",
       "4                                      NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0408d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  continent  total_cases  total_deaths  total_vaccinations  population  \\\n",
      "0      Asia       235214          7998                   0    41128772   \n",
      "1       nan     13145380        259117                   0  1426736614   \n",
      "2    Europe       335047          3605                   0     2842318   \n",
      "3    Africa       272139          6881                   0    44903228   \n",
      "4   Oceania         8359            34                   0       44295   \n",
      "\n",
      "  last_updated_date  \n",
      "0        2024-08-04  \n",
      "1        2024-08-04  \n",
      "2        2024-08-04  \n",
      "3        2024-08-04  \n",
      "4        2024-08-04  \n"
     ]
    }
   ],
   "source": [
    "columns_to_display = ['continent', 'total_cases', 'total_deaths', 'total_vaccinations', 'population','last_updated_date']\n",
    "# Show the first 5 records\n",
    "print(vaccination_data[columns_to_display].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f26d5237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/apache-spark/libexec/python/pyspark/sql/pandas/conversion.py:351: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  PyArrow >= 4.0.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+------------------+----------+-----------------+\n",
      "|    continent|total_cases|total_deaths|total_vaccinations|population|last_updated_date|\n",
      "+-------------+-----------+------------+------------------+----------+-----------------+\n",
      "|         Asia|     235214|        7998|                 0|  41128772|       2024-08-04|\n",
      "|          nan|   13145380|      259117|                 0|1426736614|       2024-08-04|\n",
      "|       Europe|     335047|        3605|                 0|   2842318|       2024-08-04|\n",
      "|       Africa|     272139|        6881|                 0|  44903228|       2024-08-04|\n",
      "|      Oceania|       8359|          34|                 0|     44295|       2024-08-04|\n",
      "|       Europe|      48015|         159|                 0|     79843|       2024-08-04|\n",
      "|       Africa|     107481|        1937|                 0|  35588996|       2024-08-04|\n",
      "|North America|       3904|          12|                 0|     15877|       2024-08-04|\n",
      "|North America|       9106|         146|                 0|     93772|       2024-08-04|\n",
      "|South America|   10101218|      130663|                 0|  45510324|       2024-08-04|\n",
      "|         Asia|     452273|        8777|                 0|   2780472|       2024-08-04|\n",
      "|North America|      44224|         292|                 0|    106459|       2024-08-04|\n",
      "|          nan|  301499099|     1637249|        9104304615|4721383370|       2024-08-14|\n",
      "|      Oceania|   11861161|       25236|                 0|  26177410|       2024-08-04|\n",
      "|       Europe|    6082444|       22534|                 0|   8939617|       2024-08-04|\n",
      "|         Asia|     835757|       10353|                 0|  10358078|       2024-08-04|\n",
      "|North America|      39127|         849|                 0|    409989|       2024-08-04|\n",
      "|         Asia|     696614|        1536|                 0|   1472237|       2024-08-04|\n",
      "|         Asia|    2051348|       29499|                 0| 171186368|       2024-08-04|\n",
      "|North America|     108582|         593|                 0|    281646|       2024-08-04|\n",
      "+-------------+-----------+------------+------------------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to Spark DataFrame directly\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"continent\", StringType(), True),\n",
    "    StructField(\"total_cases\", LongType(), True),\n",
    "    StructField(\"total_deaths\", LongType(), True),\n",
    "    StructField(\"total_vaccinations\", LongType(), True),\n",
    "    StructField(\"population\", LongType(), True),\n",
    "    StructField(\"last_updated_date\",DateType(),True)\n",
    "])\n",
    "\n",
    "# Convert the columns to the appropriate data types\n",
    "# Ensures data types and fill NaNs\n",
    "vaccination_data['continent'] = vaccination_data['continent'].astype(str)  \n",
    "vaccination_data['total_cases'] = vaccination_data['total_cases'].fillna(0).astype('int64')  \n",
    "vaccination_data['total_deaths'] = vaccination_data['total_deaths'].fillna(0).astype('int64') \n",
    "vaccination_data['total_vaccinations'] = vaccination_data['total_vaccinations'].fillna(0).astype('int64')  \n",
    "vaccination_data['population'] = vaccination_data['population'].fillna(0).astype('int64')\n",
    "vaccination_data['last_updated_date'] = vaccination_data['last_updated_date'].fillna(pd.Timestamp('2000-01-01'))\n",
    "\n",
    "\n",
    "#specified fields are taken for dataframe\n",
    "spark_df = spark.createDataFrame(vaccination_data[schema.fieldNames()]) \n",
    "# Show the Spark DataFrame\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ca37166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- continent: string (nullable = true)\n",
      " |-- total_cases: long (nullable = true)\n",
      " |-- total_deaths: long (nullable = true)\n",
      " |-- total_vaccinations: long (nullable = true)\n",
      " |-- population: long (nullable = true)\n",
      " |-- last_updated_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55f1cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+------------------+----------+-----------------+\n",
      "|continent|total_cases|total_deaths|total_vaccinations|population|last_updated_date|\n",
      "+---------+-----------+------------+------------------+----------+-----------------+\n",
      "|     Asia|     235214|        7998|                 0|  41128772|       2024-08-04|\n",
      "|      nan|   13145380|      259117|                 0|1426736614|       2024-08-04|\n",
      "|   Europe|     335047|        3605|                 0|   2842318|       2024-08-04|\n",
      "|   Africa|     272139|        6881|                 0|  44903228|       2024-08-04|\n",
      "|  Oceania|       8359|          34|                 0|     44295|       2024-08-04|\n",
      "+---------+-----------+------------+------------------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List the names of the columns you want to display\n",
    "columns_to_display = ['continent', 'total_cases', 'total_deaths', 'total_vaccinations', 'population','last_updated_date']\n",
    "# Display the first 5 records of the specified columns\n",
    "spark_df.select(columns_to_display).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47a3b7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the 'continent' and 'total_cases' columns:\n",
      "+---------+-----------+\n",
      "|continent|total_cases|\n",
      "+---------+-----------+\n",
      "|     Asia|     235214|\n",
      "|      nan|   13145380|\n",
      "|   Europe|     335047|\n",
      "|   Africa|     272139|\n",
      "|  Oceania|       8359|\n",
      "+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Displaying the 'continent' and 'total_cases' columns:\")\n",
    "# Show only the 'continent' and 'total_cases' columns\n",
    "spark_df.select('continent', 'total_cases').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38cf15f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering records where 'total_cases' is greater than 1,000,000:\n",
      "+-------------+-----------+------------+------------------+----------+-----------------+\n",
      "|    continent|total_cases|total_deaths|total_vaccinations|population|last_updated_date|\n",
      "+-------------+-----------+------------+------------------+----------+-----------------+\n",
      "|          nan|   13145380|      259117|                 0|1426736614|       2024-08-04|\n",
      "|South America|   10101218|      130663|                 0|  45510324|       2024-08-04|\n",
      "|          nan|  301499099|     1637249|        9104304615|4721383370|       2024-08-14|\n",
      "|      Oceania|   11861161|       25236|                 0|  26177410|       2024-08-04|\n",
      "|       Europe|    6082444|       22534|                 0|   8939617|       2024-08-04|\n",
      "+-------------+-----------+------------+------------------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtering records where 'total_cases' is greater than 1,000,000:\")\n",
    " # Show records with more than 1 million total cases\n",
    "spark_df.filter(spark_df['total_cases'] > 1000000).show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f04c1491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------------+---------+------------------+-----------+-----------------+\n",
      "|total_deaths|population|death_percentage|continent|total_vaccinations|total_cases|last_updated_date|\n",
      "+------------+----------+----------------+---------+------------------+-----------+-----------------+\n",
      "|        7998|  41128772|           0.02%|     Asia|                 0|     235214|       2024-08-04|\n",
      "|      259117|1426736614|           0.02%|      nan|                 0|   13145380|       2024-08-04|\n",
      "|        3605|   2842318|           0.13%|   Europe|                 0|     335047|       2024-08-04|\n",
      "|        6881|  44903228|           0.02%|   Africa|                 0|     272139|       2024-08-04|\n",
      "|          34|     44295|           0.08%|  Oceania|                 0|       8359|       2024-08-04|\n",
      "+------------+----------+----------------+---------+------------------+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark_df_with_percentage = spark_df.withColumn(\n",
    "    'death_percentage', \n",
    "    (spark_df['total_deaths'] / spark_df['population']) * 100\n",
    ")\n",
    "spark_df_with_percentage = spark_df_with_percentage.withColumn(\n",
    "    'death_percentage',\n",
    "    F.concat(\n",
    "        # Format to 2 decimal places\n",
    "        F.format_number(spark_df_with_percentage['death_percentage'], 2), \n",
    "        # Append the percentage symbol \n",
    "        F.lit('%')  \n",
    "    )\n",
    ")\n",
    "columns_to_display = ['total_deaths', 'population', 'death_percentage', 'continent', 'total_vaccinations', 'total_cases','last_updated_date']\n",
    "spark_df_with_percentage.select(columns_to_display).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db004b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+------------------+----------+-----------------+----------------+------------+\n",
      "|continent|total_cases|total_deaths|total_vaccinations|population|last_updated_date|death_percentage|updated_date|\n",
      "+---------+-----------+------------+------------------+----------+-----------------+----------------+------------+\n",
      "|     Asia|     235214|        7998|                 0|  41128772|       2024-08-04|           0.02%|        2024|\n",
      "|      nan|   13145380|      259117|                 0|1426736614|       2024-08-04|           0.02%|        2024|\n",
      "|   Europe|     335047|        3605|                 0|   2842318|       2024-08-04|           0.13%|        2024|\n",
      "|   Africa|     272139|        6881|                 0|  44903228|       2024-08-04|           0.02%|        2024|\n",
      "|  Oceania|       8359|          34|                 0|     44295|       2024-08-04|           0.08%|        2024|\n",
      "+---------+-----------+------------+------------------+----------+-----------------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, to_date\n",
    "\n",
    "spark_df_with_percentage = spark_df_with_percentage.withColumn('updated_date', year(to_date('last_updated_date','yyyy-MM-dd')))\n",
    "spark_df_with_percentage.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b825d9",
   "metadata": {},
   "source": [
    "#### UDF\n",
    "A User-Defined Function (UDF) in Spark is a custom function that you can define to perform specific transformations or calculations on your data. Spark UDFs are useful when built-in Spark functions don't provide the functionality you need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b705a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+----------------------+\n",
      "|    continent|total_deaths|converted_total_deaths|\n",
      "+-------------+------------+----------------------+\n",
      "|         Asia|        7998|                 15996|\n",
      "|          nan|      259117|                518234|\n",
      "|       Europe|        3605|                  7210|\n",
      "|       Africa|        6881|                 13762|\n",
      "|      Oceania|          34|                    68|\n",
      "|       Europe|         159|                   318|\n",
      "|       Africa|        1937|                  3874|\n",
      "|North America|          12|                    24|\n",
      "|North America|         146|                   292|\n",
      "|South America|      130663|                261326|\n",
      "|         Asia|        8777|                 17554|\n",
      "|North America|         292|                   584|\n",
      "|          nan|     1637249|               3274498|\n",
      "|      Oceania|       25236|                 50472|\n",
      "|       Europe|       22534|                 45068|\n",
      "|         Asia|       10353|                 20706|\n",
      "|North America|         849|                  1698|\n",
      "|         Asia|        1536|                  3072|\n",
      "|         Asia|       29499|                 58998|\n",
      "|North America|         593|                  1186|\n",
      "+-------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Define the UDF in Python\n",
    "def convert_total_deaths(total_deaths):\n",
    "    # Example conversion logic; replace with your own\n",
    "    return total_deaths * 2 if total_deaths is not None else 0\n",
    "\n",
    "# Register the UDF with a return type\n",
    "convert_total_deaths_udf = udf(convert_total_deaths, IntegerType())\n",
    "\n",
    "# Register the UDF in Spark SQL context\n",
    "spark.udf.register(\"convert_total_deaths\", convert_total_deaths_udf)\n",
    "\n",
    "# Drop the existing temporary view if it exists\n",
    "spark.sql(\"DROP VIEW IF EXISTS data_v\")\n",
    "\n",
    "# Create a new temporary view\n",
    "spark_df.createTempView('data_v')\n",
    "\n",
    "# Execute the SQL query using the registered UDF\n",
    "spark.sql('SELECT continent, total_deaths, convert_total_deaths(total_deaths) as converted_total_deaths FROM data_v').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb8f2e",
   "metadata": {},
   "source": [
    "RDDs (Resilient Distributed Datasets) are collections of objects similar to Python lists but with a key difference: while Python lists are processed in a single process on one machine, RDDs are distributed across multiple processes on various physical servers, or nodes, within a cluster. This setup enables RDDs to provide built-in parallelism, allowing data to be processed simultaneously across nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a15b17d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98]\n"
     ]
    }
   ],
   "source": [
    "#Create an RDD with integers from 1-50. Apply a transformation to multiply \n",
    "#every number by 2, resulting in an RDD that contains the first 50 even numbers\n",
    "\n",
    "numbers = range(1, 50) \n",
    "numbers_RDD = spark.sparkContext.parallelize(numbers) \n",
    "even_numbers_RDD = numbers_RDD.map(lambda x: x * 2)\n",
    "print( even_numbers_RDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02a7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
